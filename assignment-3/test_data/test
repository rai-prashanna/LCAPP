sc = SparkContext("local", "Simple App")
input = sc.textFile("test_data/sales.csv")
rdd = input.map(lambda line: (helper.lineSplitterByWeek(line)))
rawSalesrecord=rdd.reduceByKey(lambda x,y : int(x)+int(y)).sortByKey().collect()
CategoryMapper = helper.LoadCategoryMapper("test_data/categories.csv")
salesByname=helper.weeklyconvertIdtoItemName(rawSalesrecord,"test_data/item_categories.csv")
print(salesByname)
weeklysalesOFSubCategory=helper.weeklySalesSubCategory(salesByname,CategoryMapper)
print(weeklysalesOFSubCategory)
weeklySalesofCategory=helper.weeklysalesOfEachCategory(weeklysalesOFSubCategory,CategoryMapper)
print(weeklySalesofCategory)
